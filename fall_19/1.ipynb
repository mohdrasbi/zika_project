{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn, sklearn.ensemble, sklearn.tree, sklearn.semi_supervised, sklearn.discriminant_analysis\n",
    "import sklearn.neural_network, sklearn.gaussian_process\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Options for DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets from URLs and Mentions\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'http.?://[^\\s]+[\\s]?', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "def add_sentiment(text, text2):\n",
    "    if text2 == 4:\n",
    "        return text + \" positive\"\n",
    "    else:\n",
    "        return text + \" negative\"\n",
    "    \n",
    "def feature_eng(tweet):\n",
    "    step1 = re.sub(r'@([^:\\s]+)', r'__MENTION__', tweet)\n",
    "    output = re.sub(r'(https?://[^\\s]+)', r'__URL__', step1)\n",
    "    return output\n",
    "\n",
    "def test_multiclass_classifiers(X_train, y_train, X_test, y_test):\n",
    "    classifiers = [sklearn.naive_bayes.BernoulliNB, sklearn.tree.DecisionTreeClassifier,\n",
    "        sklearn.tree.ExtraTreeClassifier, sklearn.ensemble.ExtraTreesClassifier,\n",
    "        #sklearn.naive_bayes.GaussianNB, \n",
    "        sklearn.neighbors.KNeighborsClassifier,\n",
    "        #klearn.semi_supervised.LabelPropagation, sklearn.semi_supervised.LabelSpreading,\n",
    "        #sklearn.discriminant_analysis.LinearDiscriminantAnalysis, \n",
    "        sklearn.svm.LinearSVC,\n",
    "        sklearn.linear_model.LogisticRegression, sklearn.linear_model.LogisticRegressionCV,\n",
    "        sklearn.neural_network.MLPClassifier,  sklearn.neighbors.NearestCentroid,\n",
    "        #sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis, \n",
    "        #sklearn.neighbors.RadiusNeighborsClassifier, \n",
    "        sklearn.ensemble.RandomForestClassifier, sklearn.linear_model.RidgeClassifier, sklearn.linear_model.RidgeClassifierCV,\n",
    "        #sklearn.svm.NuSVC,\n",
    "        #sklearn.svm.SVC, sklearn.gaussian_process.GaussianProcessClassifier, \n",
    "        sklearn.ensemble.GradientBoostingClassifier,\n",
    "        sklearn.gaussian_process.GaussianProcessClassifier, sklearn.svm.LinearSVC,\n",
    "        sklearn.linear_model.LogisticRegression, sklearn.linear_model.LogisticRegressionCV,\n",
    "        sklearn.linear_model.SGDClassifier, sklearn.linear_model.Perceptron,\n",
    "        sklearn.linear_model.PassiveAggressiveClassifier]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        print(clf)\n",
    "        pipeline = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "                        (str(clf), clf())])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_predicted = pipeline.predict(X_test)\n",
    "\n",
    "        score = sum(y_test == y_predicted)/len(y_test) * 100\n",
    "        \n",
    "        print(\"Score = {:.2f}\".format(score))\n",
    "        print()\n",
    "        \n",
    "def test_multilabel_classifiers(X_train, y_train, X_test, y_test):\n",
    "    classifiers = [sklearn.tree.DecisionTreeClassifier,\n",
    "    sklearn.tree.ExtraTreeClassifier,\n",
    "    sklearn.ensemble.ExtraTreesClassifier,\n",
    "    sklearn.neighbors.KNeighborsClassifier,\n",
    "    sklearn.neural_network.MLPClassifier,\n",
    "    sklearn.ensemble.RandomForestClassifier]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        print(clf)\n",
    "        pipeline = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "                        (str(clf), clf())])\n",
    "        pipeline.fit(X_train, np.array(y_train))\n",
    "\n",
    "        y_predicted = pipeline.predict(X_test)\n",
    "\n",
    "        score = sum([np.prod(i) for i in np.array(y_predicted == y_test)])/len(y_test) * 100\n",
    "        \n",
    "        print(\"Score = {:.2f}\".format(score))\n",
    "        print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643 643\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "path = 'refilteredtweets/*.csv'\n",
    "colnames = ['tweets', 'FP']\n",
    "\n",
    "xlists = []\n",
    "ylists = []\n",
    "\n",
    "for fname in glob.glob(path):\n",
    "    tweets = pd.read_csv(fname, skipinitialspace=True, usecols=colnames)\n",
    "#     tweets['tweets'] = tweets['tweets'].apply(clean_text)\n",
    "    xlists.append(tweets['tweets'].tolist())\n",
    "    ylists.append(tweets['FP'].tolist())\n",
    "    \n",
    "    \n",
    "X = [x for xlist in xlists for x in xlist] # the element, then the outer loop first, then inner loop\n",
    "y = [y if y == 1.0 else 0.0 for ylist in ylists for y in ylist]\n",
    "\n",
    "X = [feature_eng(x) for x in X]\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Protect yourself from Zika! Wear protective clothing &amp; use approved repellents when outside. #Zika #ProtectYourself __URL__',\n",
       " 'Got bit by a mosquito. Now all I can think of is #zika.  My brain.  sigh...',\n",
       " 'Take some simple steps 2 protect yourself from the #Zika virus. __URL__ __MENTION__ __MENTION__ __URL__',\n",
       " 'Take just 2 teaspoons of 100% natural RepelZika and your entire body is protected from mosquitoes.   #RepelZika… __URL__',\n",
       " 'Fighting Zika in the US: The Battle Over GMO Mosquitoes - ABC News - __URL__ via __MENTION__',\n",
       " \"Keep spraying all those toxic pesticides &amp; you'll kill more people than Zika will. __MENTION__ __MENTION__ __URL__\",\n",
       " 'Protect your family and pets from diseases like West Nile Virus, Zika Virus, and Malaria by getting your yard sprayâ\\x80¦ __URL__',\n",
       " 'Get the real scoop on #zika and what action you can take to protect yourself and others: __URL__',\n",
       " 'See: Spike in sales of mosquito repellent products amid Zika concerns __URL__ __URL__',\n",
       " 'Take a look around your property &amp; #DrainandCover to help protect yourself and prevent #Zika __URL__']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Classify FP Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "#                     ('tfidf',TfidfTransformer(norm='l1', use_idf=True)),\n",
    "                    ('MNB',MultinomialNB(fit_prior=False))])\n",
    "#                     ('LogReg', LogisticRegression(penalty='l1'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.03305006 0.02505922 0.02404213 0.02401996 0.02434874]\n",
      "\n",
      "score_time : [0.01195478 0.00969028 0.00924897 0.00936747 0.00903106]\n",
      "\n",
      "test_precision_macro : [0.74634503 0.77284946 0.79069767 0.79282151 0.79175258]\n",
      "\n",
      "train_precision_macro : [0.98846913 0.99402985 0.9942407  0.99255952 0.99552239]\n",
      "\n",
      "test_recall_macro : [0.76479832 0.73926139 0.78156103 0.77671556 0.7300813 ]\n",
      "\n",
      "train_recall_macro : [0.98604989 0.98907104 0.99302495 0.9863388  0.99184783]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "scores = cross_validate(pipeline_1, X, y, scoring=scoring, cv=5, return_train_score=True)\n",
    "\n",
    "for k, v in scores.items():\n",
    "    print(k,\":\", v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "parameters:\n",
      "{'vect__lowercase': ('True', 'False')}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.110s\n",
      "Best score: 0.813\n",
      "Best parameters set:\n",
      "\tvect__lowercase: 'True'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    1.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__lowercase': ('True', 'False'),   \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline_1, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('MNB',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87        88\n",
      "         1.0       0.69      0.88      0.77        41\n",
      "\n",
      "    accuracy                           0.84       129\n",
      "   macro avg       0.81      0.85      0.82       129\n",
      "weighted avg       0.86      0.84      0.84       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = pipeline_1.predict(X_test)\n",
    "print(classification_report(y_predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"all_tweets/*\"):\n",
    "    tweets = list(pd.read_csv(file, lineterminator='\\n')['tweet'])\n",
    "    labels = pipeline_1.predict(tweets)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({\"tweet\": tweets, \"label\": labels})\n",
    "    filename = file.split(\"/\")[1].split(\".\")[0] + \"_labeled.csv\"\n",
    "    df.to_csv(\"classified_tweets/{}\".format(filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified_tweets/tweets_pronouns_labeled.csv\n",
      "Num tweets = 33533\n",
      "Num fp tweets = 20625\n",
      "Percentage = 61.5\n",
      "\n",
      "classified_tweets/tweets_VBG_labeled.csv\n",
      "Num tweets = 11415\n",
      "Num fp tweets = 2084\n",
      "Percentage = 18.3\n",
      "\n",
      "classified_tweets/tweets_VB_labeled.csv\n",
      "Num tweets = 4122\n",
      "Num fp tweets = 616\n",
      "Percentage = 14.9\n",
      "\n",
      "classified_tweets/tweets_VBD_labeled.csv\n",
      "Num tweets = 4299\n",
      "Num fp tweets = 760\n",
      "Percentage = 17.7\n",
      "\n",
      "classified_tweets/tweets_VBN_labeled.csv\n",
      "Num tweets = 6589\n",
      "Num fp tweets = 1069\n",
      "Percentage = 16.2\n",
      "\n",
      "classified_tweets/tweets_VBZ_labeled.csv\n",
      "Num tweets = 5185\n",
      "Num fp tweets = 1049\n",
      "Percentage = 20.2\n",
      "\n",
      "classified_tweets/tweets_VBP_labeled.csv\n",
      "Num tweets = 4781\n",
      "Num fp tweets = 866\n",
      "Percentage = 18.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"classified_tweets/*\"):\n",
    "    print(file)\n",
    "    \n",
    "    df = pd.read_csv(file, lineterminator='\\n')\n",
    "    num_tweets = len(df)\n",
    "    num_fp_tweets = sum(df['label'] == 1)\n",
    "    \n",
    "    print(\"Num tweets = {}\".format(num_tweets))\n",
    "    print(\"Num fp tweets = {}\".format(num_fp_tweets))\n",
    "    print(\"Percentage = {:.1f}\".format(num_fp_tweets/num_tweets*100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Multiple Classification\n",
    "Using only FP tweets from labeled data as training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = [\"Observe mosquito\", \"Mosquito Bite\", \"Observe spraying\", \"General spraying observation\",\n",
    "        \"Spraying for self\", \"Spraying for someone else\", \"Other kind of intervention\",\n",
    "        \"Environmental consequences\", \"Conspiracies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in glob.glob(\"refilteredtweets/*\"):\n",
    "    df = pd.concat([df, pd.read_csv(file)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_tweets = df[df[\"FP\"] == 1].fillna(0)\n",
    "X = fp_tweets[\"tweets\"]\n",
    "y = fp_tweets[y_cols]\n",
    "\n",
    "#Fix value\n",
    "y.loc[y[\"Spraying for someone else\"] == \"1?\", \"Spraying for someone else\"] = 1.0\n",
    "y = y.astype(\"float64\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class approach\n",
    "* 9 classes: 0 to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(np.array(y_train), axis=1)\n",
    "y_test = np.argmax(np.array(y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 114\n",
      "1: 9\n",
      "2: 7\n",
      "3: 7\n",
      "4: 21\n",
      "6: 2\n",
      "7: 17\n",
      "8: 6\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "for i, j in zip(values, counts):\n",
    "    print(\"{}: {}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "                    ('MNB',MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('MNB',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82        41\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           7       0.17      0.33      0.22         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.16      0.15      0.15        46\n",
      "weighted avg       0.87      0.65      0.74        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = pipeline.predict(X_test)\n",
    "print(classification_report(y_predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_multiclass_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi label approach\n",
    "* 9 labels for each row: in a form of a list [0/1, 0/1, 0/1, 0/1, 0/1, 0/1, 0/1, 0/1, 0/1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)):\n",
    "    if(sum(y_train.iloc[i]) >= 2):\n",
    "        print(list(y_train.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "Score = 56.52\n",
      "\n",
      "<class 'sklearn.tree.tree.ExtraTreeClassifier'>\n",
      "Score = 63.04\n",
      "\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "Score = 65.22\n",
      "\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Score = 63.04\n",
      "\n",
      "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "Score = 63.04\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Score = 63.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_multilabel_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add one more class: Not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observe mosquito                8.0 \n",
       "Mosquito Bite                   15.0\n",
       "Observe spraying                7.0 \n",
       "General spraying observation    8.0 \n",
       "Spraying for self               28.0\n",
       "Spraying for someone else       1.0 \n",
       "Other kind of intervention      3.0 \n",
       "Environmental consequences      23.0\n",
       "Conspiracies                    9.0 \n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols.append(\"Not classified\")\n",
    "new_y = pd.DataFrame(columns=y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    row = list(y.iloc[i])\n",
    "    if row == [0]*9:\n",
    "        row.append(1.0)\n",
    "    else:\n",
    "        row.append(0.0)\n",
    "    new_y.loc[i] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observe mosquito                8.0  \n",
       "Mosquito Bite                   15.0 \n",
       "Observe spraying                7.0  \n",
       "General spraying observation    8.0  \n",
       "Spraying for self               28.0 \n",
       "Spraying for someone else       1.0  \n",
       "Other kind of intervention      3.0  \n",
       "Environmental consequences      23.0 \n",
       "Conspiracies                    9.0  \n",
       "Not classified                  136.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi classification - 10 labels: 9 for each class, and 1 additional for unclassified rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(np.array(y_train), axis=1)\n",
    "y_test = np.argmax(np.array(y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 7\n",
      "1: 8\n",
      "2: 6\n",
      "3: 6\n",
      "4: 16\n",
      "6: 2\n",
      "7: 17\n",
      "8: 5\n",
      "9: 93\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "for i, j in zip(values, counts):\n",
    "    print(\"{}: {}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "                    ('MNB',MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('MNB',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.25      0.50      0.33         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           7       0.17      0.33      0.22         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.98      0.67      0.79        63\n",
      "\n",
      "    accuracy                           0.64        69\n",
      "   macro avg       0.15      0.17      0.15        69\n",
      "weighted avg       0.91      0.64      0.74        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = pipeline.predict(X_test)\n",
    "print(classification_report(y_predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification: multi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "Score = 46.38\n",
      "\n",
      "<class 'sklearn.tree.tree.ExtraTreeClassifier'>\n",
      "Score = 50.72\n",
      "\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "Score = 57.97\n",
      "\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Score = 59.42\n",
      "\n",
      "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "Score = 47.83\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Score = 60.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_multilabel_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification: one label vs. rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observe mosquito vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99        69\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.50      0.49      0.50        69\n",
      "weighted avg       1.00      0.99      0.99        69\n",
      "\n",
      "\n",
      "Mosquito Bite vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.97        66\n",
      "         1.0       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.94        69\n",
      "   macro avg       0.69      0.81      0.73        69\n",
      "weighted avg       0.96      0.94      0.95        69\n",
      "\n",
      "\n",
      "Observe spraying vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99        69\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.50      0.49      0.50        69\n",
      "weighted avg       1.00      0.99      0.99        69\n",
      "\n",
      "\n",
      "General spraying observation vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99        69\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97        69\n",
      "   macro avg       0.50      0.49      0.49        69\n",
      "weighted avg       1.00      0.97      0.99        69\n",
      "\n",
      "\n",
      "Spraying for self vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.88      0.93        67\n",
      "         1.0       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.87        69\n",
      "   macro avg       0.55      0.69      0.56        69\n",
      "weighted avg       0.96      0.87      0.91        69\n",
      "\n",
      "\n",
      "Spraying for someone else vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99        69\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.50      0.49      0.50        69\n",
      "weighted avg       1.00      0.99      0.99        69\n",
      "\n",
      "\n",
      "Other kind of intervention vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "\n",
      "Environmental consequences vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95        67\n",
      "         1.0       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.58      0.71      0.60        69\n",
      "weighted avg       0.96      0.91      0.93        69\n",
      "\n",
      "\n",
      "Conspiracies vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        69\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        69\n",
      "   macro avg       0.50      0.47      0.49        69\n",
      "weighted avg       1.00      0.94      0.97        69\n",
      "\n",
      "\n",
      "Not classified vs. Rest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.52      0.58        33\n",
      "         1.0       0.63      0.75      0.68        36\n",
      "\n",
      "    accuracy                           0.64        69\n",
      "   macro avg       0.64      0.63      0.63        69\n",
      "weighted avg       0.64      0.64      0.63        69\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in y_cols:\n",
    "    print(i, \"vs. Rest\")\n",
    "    temp_y = y[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, temp_y, test_size = 0.3, random_state=42)\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_predicted = pipeline.predict(X_test)\n",
    "    print(classification_report(y_predicted, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi classification: combine 0-1, 2-3, 4-5, 6-8, 9 (reduce from 9 to 5 labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New labels:\n",
    "* 0: \"Observe mosquito\" and \"Mosquito Bite\"\n",
    "* 1: \"Observe spraying\" and \"General spraying observation\"\n",
    "* 2: \"Spraying for self\" and \"Spraying for someone else\"\n",
    "* 3: \"Other kind of intervention\", \"Environmental consequences\", and \"Conspiracies\"\n",
    "* 4: Not classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = pd.DataFrame(columns=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_0 = y[\"Observe mosquito\"] + y[\"Mosquito Bite\"]\n",
    "col_0[col_0 == 2] = 1\n",
    "new_y[0] = col_0\n",
    "\n",
    "col_1 = y[\"Observe spraying\"] + y[\"General spraying observation\"]\n",
    "col_1[col_1 == 2] = 1\n",
    "new_y[1] = col_1\n",
    "\n",
    "col_2 = y[\"Spraying for self\"] + y[\"Spraying for someone else\"]\n",
    "col_2[col_2 == 2] = 1\n",
    "new_y[2] = col_2\n",
    "\n",
    "col_3 = y[\"Other kind of intervention\"] + y[\"Environmental consequences\"] + y[\"Conspiracies\"]\n",
    "col_3[col_3 == 2] = 1\n",
    "new_y[3] = col_3\n",
    "\n",
    "new_y[4] = y[\"Not classified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4\n",
       "0  0.0  0.0  0.0  1.0  0.0\n",
       "1  0.0  0.0  0.0  0.0  1.0\n",
       "2  1.0  0.0  0.0  0.0  0.0\n",
       "3  1.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(np.array(y_train), axis=1)\n",
    "y_test = np.argmax(np.array(y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 15\n",
      "1: 12\n",
      "2: 16\n",
      "3: 24\n",
      "4: 93\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "for i, j in zip(values, counts):\n",
    "    print(\"{}: {}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.44      0.80      0.57         5\n",
      "           4       0.95      0.69      0.80        59\n",
      "\n",
      "    accuracy                           0.70        69\n",
      "   macro avg       0.40      0.45      0.41        69\n",
      "weighted avg       0.88      0.70      0.77        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_2 = Pipeline([('vect',CountVectorizer(max_df=0.5, ngram_range = (1,2), lowercase = True)),\n",
    "                    ('MNB',MultinomialNB(fit_prior=False))])\n",
    "pipeline_2.fit(X_train, y_train)\n",
    "y_predicted = pipeline_2.predict(X_test)\n",
    "print(classification_report(y_predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run both classifier on all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_tweets/tweets_VBD.csv\n",
      "All tweets count: 4299\n",
      "Final tweets count: 167\n",
      "Percentage: 3.9%\n",
      "\n",
      "all_tweets/tweets_VBG.csv\n",
      "All tweets count: 11415\n",
      "Final tweets count: 616\n",
      "Percentage: 5.4%\n",
      "\n",
      "all_tweets/tweets_VBZ.csv\n",
      "All tweets count: 5185\n",
      "Final tweets count: 138\n",
      "Percentage: 2.7%\n",
      "\n",
      "all_tweets/tweets_VB.csv\n",
      "All tweets count: 4122\n",
      "Final tweets count: 93\n",
      "Percentage: 2.3%\n",
      "\n",
      "all_tweets/tweets_VBN.csv\n",
      "All tweets count: 6589\n",
      "Final tweets count: 200\n",
      "Percentage: 3.0%\n",
      "\n",
      "all_tweets/tweets_VBP.csv\n",
      "All tweets count: 4781\n",
      "Final tweets count: 146\n",
      "Percentage: 3.1%\n",
      "\n",
      "all_tweets/tweets_pronouns.csv\n",
      "All tweets count: 33533\n",
      "Final tweets count: 5649\n",
      "Percentage: 16.8%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"all_tweets/*\"):\n",
    "    print(file)\n",
    "    \n",
    "    tweets = pd.read_csv(file, lineterminator='\\n')[\"tweet\"]\n",
    "    tweets_fp = tweets[pipeline_1.predict(tweets) == 1]\n",
    "    tweets_final = tweets_fp[pipeline_2.predict(tweets_fp) != 4]\n",
    "    \n",
    "    new_file = \"final_tweets/{}\".format(file.split(\"/\")[1])\n",
    "    pd.DataFrame(columns=[\"tweets\"], data=list(tweets_final)).to_csv(new_file, index=False)\n",
    "    \n",
    "    print(\"All tweets count: {}\".format(len(tweets)))\n",
    "    print(\"Final tweets count: {}\".format(len(tweets_final)))\n",
    "    print(\"Percentage: {:.1f}%\".format(len(tweets_final)/len(tweets) * 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
