{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from difflib import SequenceMatcher\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToPrev(prev, index, text):\n",
    "    prev[index] = text\n",
    "    return prev\n",
    "\n",
    "################################\n",
    "\n",
    "def inPrev(prev, text, tot_sims):\n",
    "    for message in prev:\n",
    "        if SequenceMatcher(None, text, message).ratio() >= 0.7:\n",
    "            tot_sims.setdefault(message, []).append(text)\n",
    "            return True, tot_sims\n",
    "    return False, tot_sims\n",
    "\n",
    "################################\n",
    "\n",
    "def reduce_tweets(tweets, reduceBy): \n",
    "    prev = [\"\"]*reduceBy\n",
    "    index = 0\n",
    "    tot_sims = {}\n",
    "    filtered_tweets = []\n",
    "    \n",
    "    for _tweet in tweets:\n",
    "        in_prev, tot_sims = inPrev(prev, _tweet, tot_sims)\n",
    "        if not in_prev:\n",
    "            prev = addToPrev(prev, index, _tweet)\n",
    "            index = (index + 1) % reduceBy\n",
    "            filtered_tweets.append(_tweet)\n",
    "    \n",
    "    return filtered_tweets\n",
    "\n",
    "################################\n",
    "\n",
    "def check_sim(check_word, sims):\n",
    "    words = [\"mosquito\", \"protect\", \"repel\", \"spray\"]\n",
    "    for word in words:\n",
    "        ratio = SequenceMatcher(None, check_word, word).ratio()\n",
    "        if ratio >= 0.7:\n",
    "            sims[check_word] = ratio\n",
    "            return True, sims\n",
    "    return False, sims\n",
    "\n",
    "################################\n",
    "\n",
    "def check_sim_v2(check_word, sims, lang):\n",
    "    if re.compile('m[a-z]+sq[a-z]+to').match(check_word):\n",
    "        sims.append(check_word)\n",
    "        return True, sims\n",
    "    \n",
    "    words = ['repel', 'protect', 'spray']\n",
    "    words_es = [\"proteger\", \"repeler\", \"rociar\"]\n",
    "    words_pt = [\"proteger\", \"repelir\", \"spary\"]\n",
    "    if lang == \"es\":\n",
    "        words = words_es\n",
    "    elif lang == \"pt\":\n",
    "        words = words_pt\n",
    "        \n",
    "    for word in words:\n",
    "        if re.compile(word).search(check_word):\n",
    "            sims.append(check_word)\n",
    "            return True, sims\n",
    "    \n",
    "    return False, sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/datacsv/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_es = []\n",
    "tweets_pt = []\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "sims_es = []\n",
    "sims_pt = []\n",
    "for file in glob.glob(path):\n",
    "    df = pd.read_csv(file, sep=',', usecols=['Message', 'Language'])\n",
    "    df_tweets_es = df[df[\"Language\"] == \"es\"][\"Message\"]\n",
    "    df_tweets_pt = df[df[\"Language\"] == \"pt\"][\"Message\"]\n",
    "    \n",
    "    for tweet in df_tweets_es:\n",
    "        if tweet[0:2] != \"RT\":\n",
    "            for word in tweet.lower().split():\n",
    "                isSimilar, sims_es = check_sim_v2(regex.sub('', word), sims_es, \"es\")\n",
    "                if(isSimilar):\n",
    "                    tweets_es.append(tweet)\n",
    "                    break\n",
    "                    \n",
    "    for tweet in df_tweets_pt:\n",
    "        if tweet[0:2] != \"RT\":\n",
    "            for word in tweet.lower().split():\n",
    "                isSimilar, sims_pt = check_sim_v2(regex.sub('', word), sims_pt, \"pt\")\n",
    "                if(isSimilar):\n",
    "                    tweets_pt.append(tweet)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets that contain mosquito or a similar word is:\n",
      "es: 121373\n",
      "pt: 43401\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets that contain mosquito or a similar word is:\")\n",
    "print(\"es: {}\".format(len(tweets_es)))\n",
    "print(\"pt: {}\".format(len(tweets_pt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"tweets_es\": tweets_es}).to_csv(\"all_tweets_es.csv\")\n",
    "pd.DataFrame({\"tweets_pt\": tweets_pt}).to_csv(\"all_tweets_pt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove redundant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tweets_es = reduce_tweets(tweets_es, 10)\n",
    "filtered_tweets_pt = reduce_tweets(tweets_pt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets after prev 10 algorithm:\n",
      "es: 59810\n",
      "pt: 26770\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets after prev 10 algorithm:\")\n",
    "print(\"es: {}\".format(len(filtered_tweets_es)))\n",
    "print(\"pt: {}\".format(len(filtered_tweets_pt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"filtered_tweets_es\": filtered_tweets_es}).to_csv(\"filtered_tweets_es.csv\")\n",
    "pd.DataFrame({\"filtered_tweets_pt\": filtered_tweets_pt}).to_csv(\"filtered_tweets_pt.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"sims_es\": list(set(sims_es))}).to_csv(\"sims_es.csv\")\n",
    "pd.DataFrame({\"sims_pt\": list(set(sims_pt))}).to_csv(\"sims_pt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
